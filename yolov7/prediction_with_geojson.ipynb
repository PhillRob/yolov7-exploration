{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOsGVEPsWbbfVqHXtaHAa4G"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","source":["import rasterio\n","import os\n","# from rasterio.plot import show\n","from rasterio.windows import Window\n","import cv2\n","import gdal\n","import numpy as np\n","from matplotlib import pyplot as plt\n","import torch\n","import argparse\n","import time\n","import json\n","from pathlib import Path\n","import torch.backends.cudnn as cudnn\n","from numpy import random\n","from icecream import ic\n","\n","# import sys\n","# sys.path.append('yolov7')\n","\n","\n","from models.experimental import attempt_load\n","from utils.datasets import LoadStreams, LoadImages\n","from utils.general import check_img_size, check_requirements, check_imshow, non_max_suppression, apply_classifier, \\\n","    scale_coords, xyxy2xywh, strip_optimizer, set_logging, increment_path\n","from utils.plots import plot_one_box\n","from utils.torch_utils import select_device, load_classifier, time_synchronized, TracedModel"],"metadata":{"id":"oJInvKHIwIfE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class detect_piles():\n","  def __init__(self, weights):\n","    self.device = select_device('')\n","\n","    # load FP32 model\n","    self.model = attempt_load(weights, map_location=self.device)\n","    print(\"Model Loaded\")\n","\n","\n","  def detect(self, source_path, pred_saving_path, imgsize = 640, view_img_flag = False, save_img=False, trace_flag = False):\n","\n","    all_boxes = []\n","\n","    conf_thres = 0.5\n","    iou_thres = 0.45\n","    classes = None\n","    agnostic_nms = False\n","    save_conf = False\n","    save_txt = True\n","    nosave = False\n","    save_dir = pred_saving_path\n","\n","    source, view_img, imgsz, trace = source_path, view_img_flag, imgsize, trace_flag\n","    \n","    save_img = not nosave and not source.endswith('.txt')\n","    # webcam = source.isnumeric() or source.endswith('.txt') or source.lower().startswith(('rtsp://', 'rtmp://', 'http://', 'https://'))\n","    webcam = False\n","    set_logging()\n","    half = self.device.type != 'cpu'\n","\n","      \n","    stride = int(self.model.stride.max())  # model stride\n","    imgsz = check_img_size(imgsz, s=stride) \n","    img_size = 640\n","    \n","    if trace:\n","      self.model = TracedModel(self.model, self.device, img_size)\n","    if half:\n","      self.model.half()\n","\n","    classify = False\n","\n","    if classify:\n","      modelc = load_classifier(name='resnet101', n=2)  # initialize\n","      modelc.load_state_dict(torch.load('weights/resnet101.pt', map_location=self.device)['model']).to(self.device).eval()\n","\n","    vid_path, vid_writer = None, None\n","\n","    if webcam:\n","      view_img = check_imshow()\n","      cudnn.benchmark = True  # set True to speed up constant image size inference\n","      dataset = LoadStreams(source, img_size=imgsz, stride=stride)\n","\n","    else:\n","      dataset = LoadImages(source, img_size=imgsz, stride=stride)\n","    \n","    names = self.model.module.names if hasattr(self.model, 'module') else self.model.names\n","    # colors = [[random.randint(0, 255) for _ in range(3)] for _ in names]\n","    colors = [[0,0,255]]\n","\n","    if self.device.type != 'cpu':\n","      self.model(torch.zeros(1, 3, imgsz, imgsz).to(self.device).type_as(next(self.model.parameters())))  # run once\n","    old_img_w = old_img_h = imgsz\n","    old_img_b = 1\n","    augment = False\n","    t0 = time.time()\n","\n","    for path, img, im0s, vid_cap in dataset:\n","      img = torch.from_numpy(img).to(self.device)\n","      img = img.half() if half else img.float()  # uint8 to fp16/32\n","      img /= 255.0  # 0 - 255 to 0.0 - 1.0\n","\n","      if img.ndimension() == 3:\n","        img = img.unsqueeze(0)\n","\n","      if self.device.type != 'cpu' and (old_img_b != img.shape[0] or old_img_h != img.shape[2] or old_img_w != img.shape[3]):\n","        old_img_b = img.shape[0]\n","        old_img_h = img.shape[2]\n","        old_img_w = img.shape[3]\n","\n","        for i in range(3):\n","          self.model(img, augment=augment)[0]\n","\n","      t1 = time_synchronized()\n","\n","      with torch.no_grad():     # Calculating gradients would cause a GPU memory leak\n","        pred = self.model(img, augment=augment)[0]\n","      t2 = time_synchronized()\n","      pred = non_max_suppression(pred, conf_thres, iou_thres, classes=classes, agnostic=agnostic_nms)\n","      t3 = time_synchronized()\n","\n","      if classify:\n","        pred = apply_classifier(pred, modelc, img, im0s)\n","\n","      for i, det in enumerate(pred):\n","        if webcam:\n","          p, s, im0, frame = path[i], '%g: ' % i, im0s[i].copy(), dataset.count\n","        else:\n","          p, s, im0, frame = path, '', im0s, getattr(dataset, 'frame', 0)\n","        p = Path(p)\n","        save_path = save_dir + \"/\" + p.name\n","        # txt_path = str(save_dir + \"/\" + p.stem) + ('' if dataset.mode == 'image' else f'_{frame}')\n","        gn = torch.tensor(im0.shape)[[1, 0, 1, 0]]  # normalization gain whwh\n","        if len(det):\n","          det[:, :4] = scale_coords(img.shape[2:], det[:, :4], im0.shape).round()\n","          for c in det[:, -1].unique():\n","            n = (det[:, -1] == c).sum()\n","            s += f\"{n} {names[int(c)]}{'s' * (n > 1)}, \"\n","          for *xyxy, conf, cls in reversed(det):\n","            if save_txt:\n","              xywh = (xyxy2xywh(torch.tensor(xyxy).view(1, 4)) / gn).view(-1).tolist()\n","              all_boxes.append([xywh[0], xywh[1], xywh[2], xywh[3]])\n","              line = (cls, *xywh, conf) if save_conf else (cls, *xywh)\n","              # with open(txt_path + '.txt', 'a') as f:\n","              #   f.write(('%g ' * len(line)).rstrip() % line + '\\n')\n","\n","            if save_img or view_img:\n","              label = f'{names[int(cls)]} {conf:.2f}'\n","              plot_one_box(xyxy, im0, label=label, color=colors[int(cls)], line_thickness=1)\n","        # print(f'{s}Done. ({(1E3 * (t2 - t1)):.1f}ms) Inference, ({(1E3 * (t3 - t2)):.1f}ms) NMS')\n","        if view_img:\n","          cv2.imshow(str(p), im0)\n","          cv2.waitKey(1)\n","        ww, hh = im0.shape[1], im0.shape[0]  \n","        if save_img:\n","          if dataset.mode == 'image':\n","            cv2.imwrite(save_path, im0)\n","            print(f\" The image with the result is saved in: {save_path}\")\n","          else: \n","            if vid_path != save_path:\n","              vid_path = save_path\n","              if isinstance(vid_writer, cv2.VideoWriter):\n","                vid_writer.release()\n","              if vid_cap:\n","                fps = vid_cap.get(cv2.CAP_PROP_FPS)\n","                w = int(vid_cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n","                h = int(vid_cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n","              else: \n","                fps, w, h = 30, im0.shape[1], im0.shape[0]\n","                save_path += '.mp4'\n","              vid_writer = cv2.VideoWriter(save_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, (w, h))\n","            vid_writer.write(im0)  \n","    return all_boxes, ww, hh"],"metadata":{"id":"4PMR0wN9DfSX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class get_predictions():\n","  def __init__(self, w_path):\n","    self.pile_class = detect_piles(w_path)\n","\n","  def convert_img_array(self, data):\n","    data = torch.from_numpy(data)\n","    data=data.permute(1, 2, 0)\n","    data = data.numpy()\n","    data = cv2.cvtColor(data, cv2.COLOR_BGR2RGB)\n","    return data\n","\n","  def yolo2bbox(self, x, y, w, h, img_height, img_width):\n","    x = float(x)\n","    y = float(y)\n","    w = float(w)\n","    h = float(h)\n","    img_height = float(img_height)\n","    img_width = float(img_width)\n","    height = h * img_height\n","    width = w * img_width\n","    left = (x * img_width) - (width // 2)\n","    top = (y * img_height) - (height // 2)\n","    return round(top), round(left), round(height), round(width)\n","\n","  def resetXY(self, list_of_box, img_h, img_w, org_x, org_y):\n","    convert_x_y = []\n","    for i in list_of_box:\n","      y,x,h,w = self.yolo2bbox(i[0], i[1], i[2], i[3], img_h, img_w)\n","      convert_x_y.append([x+org_x,y+org_y,w,h])\n","    return convert_x_y\n","\n","\n","  def generate_points(self, cor_list):\n","    cnt = 0\n","    final_data = []\n","    for i in cor_list:\n","      tmp = {\"id\": \"\",\n","            \"coord\": \"\"}\n","      x,y,w,h = i\n","      p = [x,y]\n","      sp = [x+w, y]\n","      tp = [x+w, y+h]\n","      fp = [x, y+h]\n","      tmp[\"id\"] = cnt\n","      tmp[\"coord\"] = [p, sp, tp, fp]\n","      final_data.append(tmp)\n","      cnt += 1\n","    return final_data\n","\n","\n","  def convertUTM(self, file_path, list_of_coord):\n","    ds = gdal.Open(file_path)\n","\n","    cnt = 0\n","    final_data = []\n","    gt = ds.GetGeoTransform()\n","    c, a, b, f, d, e = gt\n","    for i in list_of_coord:\n","      tmp_list = []\n","      tmp = {\"id\": \"\",\n","            \"coord\": \"\"}\n","      for k in i[\"coord\"]:\n","        x, y = k[0], k[1]\n","        east = c+(a*x)\n","        north = f+(e*y)\n","        tmp_list.append([east, north])\n","      tmp[\"id\"], tmp[\"coord\"] = cnt, tmp_list\n","      final_data.append(tmp)\n","      cnt += 1\n","    return final_data\n","\n","\n","  def generate_crops(self, file_path, pred_path, json_save_path, tmp_folder, crop_size=2500):\n","\n","    if not os.path.exists(json_save_path):\n","      print(\"Not Found GeoJson Saving Path.. \\n Creating GeoJson File Saving Path...\")\n","      os.makedirs(json_save_path)\n","\n","    if not os.path.exists(tmp_folder):\n","      print(\"not found tmp folder.. \\n creating tmp folder...\")\n","      os.makedirs(tmp_folder)\n","\n","    if not os.path.exists(pred_path):\n","      print(\"not found directory for saving pedicted images.. \\n creating directory...\")\n","      os.makedirs(pred_path)\n","\n","    \n","\n","    file_name = file_path.split(\"/\")[-1].split(\".\")[0]\n","\n","    geoJson = {\n","          \"type\": \"FeatureCollection\",\n","          \"features\": []\n","        }\n","\n","    id = 0\n","\n","\n","    img = rasterio.open(file_path)\n","    profile = img.profile\n","\n","    width = profile[\"width\"]\n","    height = profile[\"height\"]\n","\n","    print(\"Total Width = \", width, \"Total Height = \", height)\n","\n","    width_cut = crop_size\n","    height_cut = crop_size\n","    step = crop_size\n","    cnt_ = 0\n","    \n","\n","    for col in range(0, height, step):\n","      if col + step >= height:\n","        height_cut = height - col\n","\n","      for row in range(0, width, step):\n","\n","        if row+width_cut >= width:\n","          final_cut = width - row\n","          data = img.read([1,2,3], window=Window(row,col, final_cut, height_cut))\n","          final_img = self.convert_img_array(data)\n","          cv2.imwrite(f'{tmp_folder}/img_{cnt_}.png', final_img)\n","          sam = f'{tmp_folder}/img_{cnt_}.png'\n","          pred_boxes, img_w, img_h = self.pile_class.detect(sam, pred_path)\n","          reset_cord = self.resetXY(pred_boxes, img_h, img_w, row, col)\n","          generate_cord = self.generate_points(reset_cord)\n","          converted_cord = self.convertUTM(file_path, generate_cord)\n","          if len(converted_cord) > 0:\n","            # ic(len(converted_cord))\n","            for i in converted_cord:\n","              tmp = {\"id\": \"\",\n","                    \"coordinates\": \"\"}\n","              tmp[\"id\"] = id\n","              tmp[\"coordinates\"] = i[\"coord\"]\n","              geoJson[\"features\"].append(tmp)\n","              id += 1\n","\n","\n","          os.remove(sam)\n","          cnt_ += 1\n","\n","        else:\n","          data = img.read([1,2,3], window=Window(row,col, width_cut, height_cut))\n","          final_img = self.convert_img_array(data)\n","          cv2.imwrite(f'{tmp_folder}/img_{cnt_}.png', final_img)\n","          sam = f'{tmp_folder}/img_{cnt_}.png'\n","          pred_boxes, img_w, img_h = self.pile_class.detect(sam, pred_path)\n","          reset_cord = self.resetXY(pred_boxes, img_h, img_w, row, col)\n","          generate_cord = self.generate_points(reset_cord)\n","          converted_cord = self.convertUTM(file_path, generate_cord)\n","          if len(converted_cord) > 0:\n","            for i in converted_cord:\n","              tmp = {\"id\": \"\",\n","                    \"coordinates\": \"\"}\n","              tmp[\"id\"] = id\n","              tmp[\"coordinates\"] = i[\"coord\"]\n","              geoJson[\"features\"].append(tmp)\n","              id += 1\n","\n","\n","          os.remove(sam)\n","          cnt_ += 1\n","    \n","    with open(f\"{json_save_path}/{file_name}.geojson\", \"a\") as outfile:\n","      json.dump(geoJson, outfile)\n"],"metadata":{"id":"1wML1evuA6wa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tiff_file1 = \"tiff_files/NamarDaharat2_Orthomosaic_export_TueAug23092831065915.tif\"\n","weights_path = \"best.pt\"\n","\n","save_pred_path = \"free_test/yolo_detected\"\n","json_saving_path  = \"free_test/generated_geo_files\"\n","tmp_file_path = \"free_test/tmp\" # use for Store images which will go to yolo model for prediction and then remove it"],"metadata":{"id":"-UFICn-zEvey"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["obj = get_predictions(weights_path)\n"],"metadata":{"id":"mu9OZlN3HB9G","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675338440300,"user_tz":-330,"elapsed":1860,"user":{"displayName":"Dev Kshatrainfotech","userId":"00316704694514822481"}},"outputId":"49b68b14-1056-44c4-a3b9-74f0e31b59b9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Fusing layers... \n","RepConv.fuse_repvgg_block\n","RepConv.fuse_repvgg_block\n","RepConv.fuse_repvgg_block\n","IDetect.fuse\n","Model Loaded\n"]}]},{"cell_type":"code","source":["obj.generate_crops(tiff_file1, save_pred_path, json_saving_path, tmp_file_path)"],"metadata":{"id":"EQqyc_ghK-vF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"LETuw_tQTnmI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"MGagCzef7ixA"},"execution_count":null,"outputs":[]}]}